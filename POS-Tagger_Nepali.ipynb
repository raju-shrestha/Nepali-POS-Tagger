{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d2095bc-5a12-41bc-b128-e6759c4f479c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'nnc_updated_ah\\\\cs\\\\a17.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01metree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mElementTree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mET\u001b[39;00m\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnnc_updated_ah\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcs\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124ma17.xml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m filelist \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(path)\n\u001b[0;32m      7\u001b[0m tags \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m filelist:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'nnc_updated_ah\\\\cs\\\\a17.xml'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "path = 'nnc_updated_ah\\\\cs\\\\a17.xml'\n",
    "filelist = os.listdir(path)\n",
    "\n",
    "tags = []\n",
    "\n",
    "for file in filelist:\n",
    "    filepath = os.path.join(path, file)\n",
    "    print(filepath)\n",
    "\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for data in root.findall('text'):\n",
    "        for value in data:\n",
    "            # print(value.tag)\n",
    "            if (value.tag == 'group'):\n",
    "                # for group in value.findall('group'):\n",
    "                for body in value.findall('body'):\n",
    "                    for div in body.findall('div'):\n",
    "                        for subdiv in div:\n",
    "                            # print(subdiv.tag)\n",
    "                            if (subdiv.tag == \"head\"):\n",
    "                                for sentence in subdiv.findall('s'):\n",
    "                                    # print(sentence.attrib)\n",
    "                                    for s in sentence:\n",
    "                                        # print(s.attrib)\n",
    "                                        if (s.tag == \"foreign\"):\n",
    "                                            for words in s.findall('w'):\n",
    "                                                tags.append(words.attrib['ctag'])\n",
    "                                                print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                        # print(\"\\n\")\n",
    "                                        if (s.tag == \"w\"):\n",
    "                                            tags.append(s.attrib['ctag'])\n",
    "                                            print(\"%s/%s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                            # countTags(tags,s.attrib['ctag'])\n",
    "                                    print('\\n')\n",
    "\n",
    "                            if (subdiv.tag == \"p\"):\n",
    "                                for sentence in subdiv.findall('s'):\n",
    "                                    print(sentence.attrib)\n",
    "                                    for s in sentence:\n",
    "                                        if (s.tag == \"foreign\"):\n",
    "                                            for words in s.findall('w'):\n",
    "                                                tags.append(words.attrib['ctag'])\n",
    "                                                print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                                # countTags(tags,words.attrib['ctag'])\n",
    "                                        # print(\"\\n\")\n",
    "                                        if (s.tag == \"w\"):\n",
    "                                            tags.append(s.attrib['ctag'])\n",
    "                                            print(\"%s/%s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                            # countTags(tags,s.attrib['ctag'])\n",
    "                                    print('\\n')\n",
    "            if (value.tag == 'body'):\n",
    "                # for body in value.findall('body'):\n",
    "                for div in value.findall('div'):\n",
    "                    for subdiv in div:\n",
    "                        # print(subdiv.tag)\n",
    "                        if (subdiv.tag == \"head\"):\n",
    "                            for sentence in subdiv.findall('s'):\n",
    "                                print(sentence.attrib)\n",
    "                                for s in sentence:\n",
    "                                    # print(s.attrib)\n",
    "                                    if (s.tag == \"foreign\"):\n",
    "                                        for words in s.findall('w'):\n",
    "                                            tags.append(words.attrib['ctag'])\n",
    "                                            print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                            # countTags(tags,words.attrib['ctag'])\n",
    "                                    # print(\"\\n\")\n",
    "                                    if (s.tag == \"w\"):\n",
    "                                        tags.append(s.attrib['ctag'])\n",
    "                                        print(\"%s/%s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                        # countTags(tags,s.attrib['ctag'])\n",
    "                                print('\\n')\n",
    "\n",
    "                        if (subdiv.tag == \"p\"):\n",
    "                            for sentence in subdiv.findall('s'):\n",
    "                                print(sentence.attrib)\n",
    "                                for s in sentence:\n",
    "                                    if (s.tag == \"foreign\"):\n",
    "                                        for words in s.findall('w'):\n",
    "                                            tags.append(words.attrib['ctag'])\n",
    "                                            print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                            # countTags(tags,words.attrib['ctag'])\n",
    "                                    # print(\"\\n\")\n",
    "                                    if (s.tag == \"w\"):\n",
    "                                        tags.append(s.attrib['ctag'])\n",
    "                                        print(\"%s/%s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                        # countTags(tags,s.attrib['ctag'])\n",
    "                                print('\\n')\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ff1f80-ef44-45ba-b4cb-6d9e9fd47961",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Numbers of Tags\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tags)\n\u001b[0;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tags:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tags' is not defined"
     ]
    }
   ],
   "source": [
    "# Numbers of Tags\n",
    "print(tags)\n",
    "output = set()\n",
    "for x in tags:\n",
    "    output.add(x)\n",
    "print(\"Number of tags:\", len(output))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26abe654-2163-42d7-8702-d860e1b9c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(tokens, index):\n",
    "    word = tokens[index]\n",
    "    pos = tokens[index + 1]\n",
    "    if index == 0:\n",
    "        prevword = ''\n",
    "        prevpos = ''\n",
    "        prevprevword = ''\n",
    "        prevprevpos = ''\n",
    "    elif index == 2:\n",
    "        prevword = tokens[index - 2]\n",
    "        prevpos = tokens[index - 1]\n",
    "        prevprevword = ''\n",
    "        prevprevpos = ''\n",
    "    else:\n",
    "        prevword = tokens[index - 2]\n",
    "        prevpos = tokens[index - 1]\n",
    "        prevprevword = tokens[index - 4]\n",
    "        prevprevpos = tokens[index - 3]\n",
    "\n",
    "    if index == len(tokens) - 2:\n",
    "        nextword = ''\n",
    "        nextpos = ''\n",
    "        nextnextword = ''\n",
    "        nextnextpos = ''\n",
    "    elif index == len(tokens) - 4:\n",
    "        nextword = tokens[index + 2]\n",
    "        nextpos = tokens[index + 3]\n",
    "        nextnextword = ''\n",
    "        nextnextpos = ''\n",
    "    else:\n",
    "        nextword = tokens[index + 2]\n",
    "        nextpos = tokens[index + 3]\n",
    "        nextnextword = tokens[index + 4]\n",
    "        nextnextpos = tokens[index + 5]\n",
    "\n",
    "    features = {'feature': {'word': word, 'pos': pos, 'next-word': nextword, 'next-pos': nextpos,\n",
    "                            'next-next-word': nextnextword,\n",
    "                            'next-next-pos': nextnextpos, 'prev-word': prevword, 'prev-pos': prevpos,\n",
    "                            'prev-prev-word': prevprevword,\n",
    "                            'prev-prev-pos': prevprevpos}, 'pos': pos}\n",
    "\n",
    "    return {\n",
    "        'word': word,\n",
    "        'pos': pos,\n",
    "\n",
    "        'next-word': nextword,\n",
    "        'next-pos': nextpos,\n",
    "\n",
    "        'next-next-word': nextnextword,\n",
    "        'nextnextpos': nextnextpos,\n",
    "\n",
    "        'prev-word': prevword,\n",
    "        'prev-pos': prevpos,\n",
    "\n",
    "        'prev-prev-word': prevprevword,\n",
    "        'prev-prev-pos': prevprevpos,\n",
    "    }\n",
    "\n",
    "def get_wordFeatures(tokens, index):\n",
    "    word = tokens[index]\n",
    "    # pos = tokens[index + 1]\n",
    "\n",
    "    if index == 0:\n",
    "        prevword = ''\n",
    "        prevprevword = ''\n",
    "    elif index == 1:\n",
    "        prevword = tokens[index - 1]\n",
    "        prevprevword = ''\n",
    "    else:\n",
    "        prevword = tokens[index - 1]\n",
    "        prevprevword = tokens[index - 2]\n",
    "\n",
    "    if index == len(tokens) - 1:\n",
    "        nextword = ''\n",
    "        nextnextword = ''\n",
    "\n",
    "    elif index == len(tokens) - 2:\n",
    "        nextword = tokens[index + 1]\n",
    "        nextnextword = ''\n",
    "\n",
    "    else:\n",
    "        nextword = tokens[index + 1]\n",
    "        nextnextword = tokens[index + 2]\n",
    "\n",
    "    return {\n",
    "        'word': word,\n",
    "        # 'pos': '',\n",
    "\n",
    "        'next-word': nextword,\n",
    "        # 'next-pos': '',\n",
    "\n",
    "        'next-next-word': nextnextword,\n",
    "        # 'nextnextpos': '',\n",
    "\n",
    "        'prev-word': prevword,\n",
    "        # 'prev-pos': '',\n",
    "\n",
    "        'prev-prev-word': prevprevword,\n",
    "        # 'prev-prev-pos': '',\n",
    "    }\n",
    "\n",
    "def get_testfeatures(tokens, index):\n",
    "    word = tokens[index]\n",
    "\n",
    "    if index == 0:\n",
    "        prevword = ''\n",
    "        prevprevword = ''\n",
    "\n",
    "    elif index == 2:\n",
    "        prevword = tokens[index - 2]\n",
    "        prevprevword = ''\n",
    "\n",
    "    else:\n",
    "        prevword = tokens[index - 2]\n",
    "        prevprevword = tokens[index - 4]\n",
    "\n",
    "    if index == len(tokens) - 2:\n",
    "        nextword = ''\n",
    "        nextnextword = ''\n",
    "\n",
    "    elif index == len(tokens) - 4:\n",
    "        nextword = tokens[index + 2]\n",
    "        nextnextword = ''\n",
    "    else:\n",
    "        nextword = tokens[index + 2]\n",
    "        nextnextword = tokens[index + 4]\n",
    "\n",
    "    return {\n",
    "        'word': word,\n",
    "        # 'pos': '',\n",
    "\n",
    "        'next-word': nextword,\n",
    "        # 'next-pos': '',\n",
    "\n",
    "        'next-next-word': nextnextword,\n",
    "        # 'nextnextpos': '',\n",
    "\n",
    "        'prev-word': prevword,\n",
    "        # 'prev-pos': '',\n",
    "\n",
    "        'prev-prev-word': prevprevword,\n",
    "        # 'prev-prev-pos': '',\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9552a4b-5875-434f-a3ba-392998c79522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['संसद', 'को', 'अधिवेशन', 'आषाढ', 'को', 'शुरु', 'मा', 'हुने', 'राष्ट्रियसभा', 'को', 'गठन', 'यै', 'महिना', 'मा', 'भईसक्ने', 'चीन-सोभियत', 'सीमा', 'मा', 'बढी', 'सबल', 'सुरक्षा'] [{'word': 'संसद', 'next-word': 'को', 'next-next-word': 'अधिवेशन', 'prev-word': '', 'prev-prev-word': ''}, {'word': 'को', 'next-word': 'अधिवेशन', 'next-next-word': 'आषाढ', 'prev-word': 'संसद', 'prev-prev-word': ''}, {'word': 'अधिवेशन', 'next-word': 'आषाढ', 'next-next-word': 'को', 'prev-word': 'को', 'prev-prev-word': 'संसद'}, {'word': 'आषाढ', 'next-word': 'को', 'next-next-word': 'शुरु', 'prev-word': 'अधिवेशन', 'prev-prev-word': 'को'}, {'word': 'को', 'next-word': 'शुरु', 'next-next-word': 'मा', 'prev-word': 'आषाढ', 'prev-prev-word': 'अधिवेशन'}, {'word': 'शुरु', 'next-word': 'मा', 'next-next-word': 'हुने', 'prev-word': 'को', 'prev-prev-word': 'आषाढ'}, {'word': 'मा', 'next-word': 'हुने', 'next-next-word': 'राष्ट्रियसभा', 'prev-word': 'शुरु', 'prev-prev-word': 'को'}, {'word': 'हुने', 'next-word': 'राष्ट्रियसभा', 'next-next-word': 'को', 'prev-word': 'मा', 'prev-prev-word': 'शुरु'}, {'word': 'राष्ट्रियसभा', 'next-word': 'को', 'next-next-word': 'गठन', 'prev-word': 'हुने', 'prev-prev-word': 'मा'}, {'word': 'को', 'next-word': 'गठन', 'next-next-word': 'यै', 'prev-word': 'राष्ट्रियसभा', 'prev-prev-word': 'हुने'}, {'word': 'गठन', 'next-word': 'यै', 'next-next-word': 'महिना', 'prev-word': 'को', 'prev-prev-word': 'राष्ट्रियसभा'}, {'word': 'यै', 'next-word': 'महिना', 'next-next-word': 'मा', 'prev-word': 'गठन', 'prev-prev-word': 'को'}, {'word': 'महिना', 'next-word': 'मा', 'next-next-word': 'भईसक्ने', 'prev-word': 'यै', 'prev-prev-word': 'गठन'}, {'word': 'मा', 'next-word': 'भईसक्ने', 'next-next-word': 'चीन-सोभियत', 'prev-word': 'महिना', 'prev-prev-word': 'यै'}, {'word': 'भईसक्ने', 'next-word': 'चीन-सोभियत', 'next-next-word': 'सीमा', 'prev-word': 'मा', 'prev-prev-word': 'महिना'}, {'word': 'चीन-सोभियत', 'next-word': 'सीमा', 'next-next-word': 'मा', 'prev-word': 'भईसक्ने', 'prev-prev-word': 'मा'}, {'word': 'सीमा', 'next-word': 'मा', 'next-next-word': 'बढी', 'prev-word': 'चीन-सोभियत', 'prev-prev-word': 'भईसक्ने'}, {'word': 'मा', 'next-word': 'बढी', 'next-next-word': 'सबल', 'prev-word': 'सीमा', 'prev-prev-word': 'चीन-सोभियत'}, {'word': 'बढी', 'next-word': 'सबल', 'next-next-word': 'सुरक्षा', 'prev-word': 'मा', 'prev-prev-word': 'सीमा'}, {'word': 'सबल', 'next-word': 'सुरक्षा', 'next-next-word': '', 'prev-word': 'बढी', 'prev-prev-word': 'मा'}, {'word': 'सुरक्षा', 'next-word': '', 'next-next-word': '', 'prev-word': 'सबल', 'prev-prev-word': 'बढी'}]\n",
      "Converting word features into Numpy arrays\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]]\n",
      "Converting test word features into Numpy arrays\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]]\n",
      "129 84\n",
      "Support vectors\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 1.]]\n",
      "No of Support Vectors\n",
      "[ 1  1  1  5  8  1  6  1 17  3  3  2  1  1  1  1]\n",
      "Support vector indices\n",
      "[39 40 21  2 16 31 41 46  6  9 14 26 33 37 44 50 12  0  3 10 23 35 47 22\n",
      "  1  4  7  8 11 13 15 17 24 25 27 32 34 36 38 43 45 18 19 20  5 30 49 29\n",
      " 48 42 28 51 52]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import ExtractFeatures\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "path = 'nnc_updated_ah\\\\cs\\\\a07.xml'\n",
    "\n",
    "X, y, X_test, y_test, test_sen, train_sen = [], [], [], [], [], []\n",
    "temp = 0\n",
    "\n",
    "\n",
    "trainFeatures = [{'prev-word': '', 'next-word': 'निर्वाचन', 'word': 'आम'}, {'prev-word': 'आम', 'next-word': 'मा', 'word': 'निर्वाचन'}, {'prev-word': 'निर्वाचन', 'next-word': 'स्पष्ट', 'word': 'मा'}, {'prev-word': 'मा', 'next-word': 'बहुमत', 'word': 'स्पष्ट'}, {'prev-word': 'स्पष्ट', 'next-word': 'ल्याए', 'word': 'बहुमत'}, {'prev-word': 'बहुमत', 'next-word': 'को', 'word': 'ल्याए'}, {'prev-word': 'ल्याए', 'next-word': 'नेपाली', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'काँग्रेस', 'word': 'नेपाली'}, {'prev-word': 'नेपाली', 'next-word': 'को', 'word': 'काँग्रेस'}, {'prev-word': 'काँग्रेस', 'next-word': 'संसदीय', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'दल', 'word': 'संसदीय'}, {'prev-word': 'संसदीय', 'next-word': 'का', 'word': 'दल'}, {'prev-word': 'दल', 'next-word': 'नेता', 'word': 'का'}, {'prev-word': 'का', 'next-word': 'को', 'word': 'नेता'}, {'prev-word': 'नेता', 'next-word': 'रुप', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'मा', 'word': 'रुप'}, {'prev-word': 'रुप', 'next-word': 'श्री', 'word': 'मा'}, {'prev-word': 'मा', 'next-word': 'गिरीजा', 'word': 'श्री'}, {'prev-word': 'श्री', 'next-word': 'प्रसाद', 'word': 'गिरीजा'}, {'prev-word': 'गिरीजा', 'next-word': 'कोइराला', 'word': 'प्रसाद'}, {'prev-word': 'प्रसाद', 'next-word': 'ले', 'word': 'कोइराला'}, {'prev-word': 'कोइराला', 'next-word': 'पन्द्रह', 'word': 'ले'}, {'prev-word': 'ले', 'next-word': 'सदस्यीय', 'word': 'पन्द्रह'}, {'prev-word': 'पन्द्रह', 'next-word': 'मन्त्रि', 'word': 'सदस्यीय'}, {'prev-word': 'सदस्यीय', 'next-word': 'परिषद', 'word': 'मन्त्रि'}, {'prev-word': 'मन्त्रि', 'next-word': 'को', 'word': 'परिषद'}, {'prev-word': 'परिषद', 'next-word': 'गठन', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'गरी', 'word': 'गठन'}, {'prev-word': 'गठन', 'next-word': 'सक्नु', 'word': 'गरी'}, {'prev-word': 'गरी', 'next-word': 'भए', 'word': 'सक्नु'}, {'prev-word': 'सक्नु', 'next-word': 'पछि', 'word': 'भए'}, {'prev-word': 'भए', 'next-word': 'मुलुक', 'word': 'पछि'}, {'prev-word': 'पछि', 'next-word': 'को', 'word': 'मुलुक'}, {'prev-word': 'मुलुक', 'next-word': 'ध्यान', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'राष्ट्रिय', 'word': 'ध्यान'}, {'prev-word': 'ध्यान', 'next-word': 'सभा', 'word': 'राष्ट्रिय'}, {'prev-word': 'राष्ट्रिय', 'next-word': 'को', 'word': 'सभा'}, {'prev-word': 'सभा', 'next-word': 'गठन', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'र', 'word': 'गठन'}, {'prev-word': 'गठन', 'next-word': 'त्यस', 'word': 'र'}, {'prev-word': 'र', 'next-word': 'पछि', 'word': 'त्यस'}, {'prev-word': 'त्यस', 'next-word': 'हुने', 'word': 'पछि'}, {'prev-word': 'पछि', 'next-word': 'संसद', 'word': 'हुने'}, {'prev-word': 'हुने', 'next-word': 'को', 'word': 'संसद'}, {'prev-word': 'संसद', 'next-word': 'अधिवेशन', 'word': 'को'}, {'prev-word': 'को', 'next-word': 'तिर', 'word': 'अधिवेशन'}, {'prev-word': 'अधिवेशन', 'next-word': 'केन्द्रित', 'word': 'तिर'}, {'prev-word': 'तिर', 'next-word': 'हुन', 'word': 'केन्द्रित'}, {'prev-word': 'केन्द्रित', 'next-word': 'थाले', 'word': 'हुन'}, {'prev-word': 'हुन', 'next-word': 'को', 'word': 'थाले'}, {'prev-word': 'थाले', 'next-word': 'छ', 'word': 'को'}, {'prev-word': 'को', 'next-word': '।', 'word': 'छ'}, {'prev-word': 'छ', 'next-word': '', 'word': '।'}]\n",
    "trainLabels = ['JX', 'NN', 'II', 'JX', 'NN', 'VE', 'IKM', 'NN', 'NN', 'IKM', 'JX', 'NN', 'IKO', 'NN', 'IKM', 'NN', 'II', 'NN', 'NP', 'NP', 'NP', 'IE', 'MM', 'JX', 'NN', 'NN', 'IKM', 'NN', 'VR', 'VI', 'VE', 'II', 'NN', 'IKM', 'NN', 'JX', 'NN', 'IKM', 'NN', 'CC', 'DDX', 'II', 'VN', 'NN', 'IKM', 'NN', 'II', 'JX', 'VI', 'VE', 'IKM', 'VVYN1', 'YF']\n",
    "test_feat =[]\n",
    "test = ['संसद', 'को', 'अधिवेशन', 'आषाढ', 'को', 'शुरु', 'मा', 'हुने', 'राष्ट्रियसभा', 'को', 'गठन', 'यै', 'महिना', 'मा', 'भईसक्ने', 'चीन-सोभियत', 'सीमा', 'मा', 'बढी', 'सबल', 'सुरक्षा']\n",
    "# test = [{'pos': 'IKM', 'prev-prev-word': 'अधिवेशन', 'word': 'को', 'prev-word': 'आषाढ', 'prev-pos': 'NN', 'next-next-word': 'मा', 'prev-prev-pos': 'NN', 'next-pos': 'NN', 'next-word': 'शुरु', 'nextnextpos': 'II'}]\n",
    "for x in range(0, len(test)):\n",
    "    test_feat.append(ExtractFeatures.get_wordFeatures(test, x))\n",
    "print(test, test_feat)\n",
    "\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_arr = vec.fit_transform(trainFeatures)\n",
    "print(\"Converting word features into Numpy arrays\")\n",
    "print(X_arr)\n",
    "XTest_arr = vec.fit_transform(test_feat)\n",
    "print(\"Converting test word features into Numpy arrays\")\n",
    "print(XTest_arr)\n",
    "\n",
    "\n",
    "print(X_arr.shape[1], XTest_arr.shape[1])\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(X_arr, trainLabels)\n",
    "\n",
    "print(\"Support vectors\")\n",
    "print(clf.support_vectors_)\n",
    "with open(\"support.txt\", \"wb\") as f:\n",
    "    np.savetxt(f, clf.support_vectors_)\n",
    "    f.close()\n",
    "print(\"No of Support Vectors\")\n",
    "print(clf.n_support_)\n",
    "print(\"Support vector indices\")\n",
    "print(clf.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0e3e7e6-e42a-4a17-85b8-feafec97e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': '1'}\n",
      "['संसद', 'NN', 'को', 'IKM', 'अधिवेशन', 'NN', 'आषाढ', 'NN', 'को', 'IKM', 'शुरु', 'NN', 'मा', 'II', 'हुने', 'VN', 'राष्ट्रियसभा', 'NN', 'को', 'IKM', 'गठन', 'NN', 'यै', 'DDX', 'महिना', 'NN', 'मा', 'II', 'भईसक्ने', 'VN']\n",
      "{'n': '18'}\n",
      "['चीन-सोभियत', 'NP', 'सीमा', 'NN', 'मा', 'II', 'बढी', 'JX', 'सबल', 'JX', 'सुरक्षा', 'NN']\n",
      "{'n': '36'}\n",
      "['राष्ट्रिय', 'JX', 'जनगणना', 'NN', 'को', 'IKM', 'महत्व', 'NN']\n",
      "{'n': '46'}\n",
      "['भारत', 'NP', 'र', 'CC', 'नेपाल', 'NP', 'को', 'IKM', 'वार्ता', 'NN', 'विवाद', 'NN', 'को', 'IKM', 'जाल', 'NN', 'मा', 'II']\n",
      "{'n': '64'}\n",
      "['राष्ट्र', 'NN', 'बैंक', 'NN', 'मा', 'II', 'कर्मचारी', 'NN', 'निलम्बित', 'JX']\n",
      "{'n': '81'}\n",
      "['त्रिभुवन', 'NP', 'विश्वविद्यालय', 'NN', 'मा', 'II', 'राजिनामा', 'NN', 'को', 'IKM', 'लहर', 'NN']\n",
      "{'n': '82'}\n",
      "['उपकुलपति', 'NN', 'र', 'CC', 'पदाधिकारी', 'NN', 'हरु', 'IH', 'को', 'IKM', 'नयाँ', 'JX', 'नियुक्ति', 'NN', 'हुने', 'VN', '?', 'YF']\n",
      "{'n': '91'}\n",
      "['मुस्लिम', 'NN', 'र', 'CC', 'हिन्दु', 'NN', 'को', 'IKM', 'दंगा', 'NN']\n",
      "{'n': '92'}\n",
      "['पार्टी', 'NN', 'हरु', 'IH', 'को', 'IKM', 'दिबालियापन', 'NN', 'को', 'IKM', 'परिणाम', 'NN']\n",
      "2685 65\n",
      "2685 65\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ExtractFeatures\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "path = 'nnc_updated_ah\\\\cs\\\\a17.xml'\n",
    "\n",
    "X, y, X_test, y_test, test_sen = [], [], [], [], []\n",
    "temp = 0\n",
    "\n",
    "tree = ET.parse(path)\n",
    "root = tree.getroot()\n",
    "single_sentence = []\n",
    "\n",
    "for data in root.findall('text'):\n",
    "            for value in data:\n",
    "                # print(value.tag)\n",
    "                if (value.tag == 'group'):\n",
    "                    # for group in value.findall('group'):\n",
    "                    for body in value.findall('body'):\n",
    "                        for div in body.findall('div'):\n",
    "                            for subdiv in div:\n",
    "                                # print(subdiv.tag)\n",
    "                                if (subdiv.tag == \"head\"):\n",
    "\n",
    "                                    for sentence in subdiv.findall('s'):\n",
    "                                        print(sentence.attrib)\n",
    "                                        single_sentence = []\n",
    "                                        for s in sentence:\n",
    "                                            # print(s.attrib)\n",
    "                                            if (s.tag == \"foreign\"):\n",
    "                                                for words in s.findall('w'):\n",
    "                                                    print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                            # print(\"\\n\")\n",
    "                                            if (s.tag == \"w\"):\n",
    "                                                # print(\"%s %s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                                single_sentence.append(s.text)\n",
    "                                                single_sentence.append(s.attrib['ctag'])\n",
    "                                                test_sen.append(s.text)\n",
    "                                                y_test.append(s.attrib['ctag'])\n",
    "                                        print(single_sentence)\n",
    "\n",
    "                                        for x in range(0, len(single_sentence), 2):\n",
    "                                            # print(get_features(single_sentence,x))\n",
    "                                            X_test.append(ExtractFeatures.get_testfeatures(single_sentence, x))\n",
    "                                #         # print('\\n')\n",
    "                                # print(len(single_sentence))\n",
    "                                if (subdiv.tag == \"p\"):\n",
    "                                    for sentence in subdiv.findall('s'):\n",
    "                                        # print(sentence.attrib)\n",
    "                                        single_sentence = []\n",
    "                                        for s in sentence:\n",
    "                                            if (s.tag == \"foreign\"):\n",
    "                                                for words in s.findall('w'):\n",
    "                                                  print(\"%s/%s\" % (words.text, words.attrib['ctag']), '', end=''),\n",
    "                                            # print(\"\\n\")\n",
    "                                            if (s.tag == \"w\"):\n",
    "                                                temp = temp+1\n",
    "                                                # print(\"%s/%s\" % (s.text, s.attrib['ctag']), '', end=''),\n",
    "                                                single_sentence.append(s.text)\n",
    "                                                single_sentence.append(s.attrib['ctag'])\n",
    "                                                y.append(s.attrib['ctag'])\n",
    "\n",
    "                                        for x in range(0, len(single_sentence), 2):\n",
    "                                            X.append(ExtractFeatures.get_testfeatures(single_sentence, x))\n",
    "                                            # temp = temp + 1\n",
    "\n",
    "    # print(temp)\n",
    "print(len(X), len(X_test))\n",
    "print(len(y), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a6df6a1-0575-444f-8d6c-4e06cf492223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['संसद', 'को', 'अधिवेशन', 'आषाढ', 'को', 'शुरु', 'मा', 'हुने', 'राष्ट्रियसभा', 'को', 'गठन', 'यै', 'महिना', 'मा', 'भईसक्ने', 'चीन-सोभियत', 'सीमा', 'मा', 'बढी', 'सबल', 'सुरक्षा', 'राष्ट्रिय', 'जनगणना', 'को', 'महत्व', 'भारत', 'र', 'नेपाल', 'को', 'वार्ता', 'विवाद', 'को', 'जाल', 'मा', 'राष्ट्र', 'बैंक', 'मा', 'कर्मचारी', 'निलम्बित', 'त्रिभुवन', 'विश्वविद्यालय', 'मा', 'राजिनामा', 'को', 'लहर', 'उपकुलपति', 'र', 'पदाधिकारी', 'हरु', 'को', 'नयाँ', 'नियुक्ति', 'हुने', '?', 'मुस्लिम', 'र', 'हिन्दु', 'को', 'दंगा', 'पार्टी', 'हरु', 'को', 'दिबालियापन', 'को', 'परिणाम']\n",
      "['NN' 'IKM' 'NN' 'NN' 'IKM' 'NN' 'II' 'VN' 'NN' 'IKM' 'NN' 'NN' 'NN' 'II'\n",
      " 'YF' 'NP' 'NN' 'II' 'NN' 'NN' 'YF' 'JX' 'NN' 'IKM' 'NN' 'NP' 'CC' 'NP'\n",
      " 'IKM' 'NN' 'NN' 'IKM' 'NN' 'II' 'NN' 'NN' 'II' 'NN' 'YF' 'DDX' 'NN' 'II'\n",
      " 'NN' 'IKM' 'YF' 'NN' 'CC' 'NN' 'IH' 'IKM' 'JX' 'NN' 'VN' 'YF' 'NN' 'CC'\n",
      " 'NN' 'IKM' 'NN' 'NN' 'IH' 'IKM' 'NN' 'IKM' 'YF']\n",
      "Accuracy: 86.15384615384616 %\n",
      "संसद/NN को/IKM अधिवेशन/NN आषाढ/NN को/IKM शुरु/NN मा/II हुने/VN राष्ट्रियसभा/NN को/IKM गठन/NN यै/NN महिना/NN मा/II भईसक्ने/YF चीन-सोभियत/NP सीमा/NN मा/II बढी/NN सबल/NN सुरक्षा/YF राष्ट्रिय/JX जनगणना/NN को/IKM महत्व/NN भारत/NP र/CC नेपाल/NP को/IKM वार्ता/NN विवाद/NN को/IKM जाल/NN मा/II राष्ट्र/NN बैंक/NN मा/II कर्मचारी/NN निलम्बित/YF त्रिभुवन/DDX विश्वविद्यालय/NN मा/II राजिनामा/NN को/IKM लहर/YF उपकुलपति/NN र/CC पदाधिकारी/NN हरु/IH को/IKM नयाँ/JX नियुक्ति/NN हुने/VN ?/YF मुस्लिम/NN र/CC हिन्दु/NN को/IKM दंगा/NN पार्टी/NN हरु/IH को/IKM दिबालियापन/NN को/IKM परिणाम/YF "
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "            ('vectorizer', DictVectorizer(sparse=False)),\n",
    "            ('classifier', LinearSVC())\n",
    "        ])\n",
    "clf.fit(X[:50000],y[:50000])\n",
    "\n",
    "y_predict = (clf.predict(X_test))\n",
    "print(test_sen)\n",
    "print(y_predict)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy * 100, '%')\n",
    "\n",
    "for x in range(0, len(test_sen)):\n",
    "     print(\"%s/%s\" % (test_sen[x], y_predict[x]),'', end='')\n",
    "\n",
    "import pickle\n",
    "pickle.dump(clf, open(\"RESULT.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffb888fb-45ab-43af-81e6-afa90d3f3d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       1.00      1.00      1.00         3\n",
      "         DDX       0.00      0.00      0.00         1\n",
      "          IH       1.00      1.00      1.00         2\n",
      "          II       1.00      1.00      1.00         6\n",
      "         IKM       1.00      1.00      1.00        11\n",
      "          JX       1.00      0.40      0.57         5\n",
      "          NN       0.90      0.90      0.90        29\n",
      "          NP       1.00      0.75      0.86         4\n",
      "          VN       1.00      0.67      0.80         3\n",
      "          YF       0.17      1.00      0.29         1\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.81      0.77      0.74        65\n",
      "weighted avg       0.93      0.86      0.88        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\\n\",\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0db0d9b5-99df-4592-b8c6-bac696c6fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  6  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 11  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  2  2  0  0  1]\n",
      " [ 0  0  0  0  0  0 26  0  0  3]\n",
      " [ 0  1  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9605305e-ca39-4f6b-b80e-f02eed3e8751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  CC  DDX  IH  II  IKM  JX  NN  NP  VN  YF\n",
      "Actual                                             \n",
      "CC          3    0   0   0    0   0   0   0   0   0\n",
      "DDX         0    0   0   0    0   0   1   0   0   0\n",
      "IH          0    0   2   0    0   0   0   0   0   0\n",
      "II          0    0   0   6    0   0   0   0   0   0\n",
      "IKM         0    0   0   0   11   0   0   0   0   0\n",
      "JX          0    0   0   0    0   2   2   0   0   1\n",
      "NN          0    0   0   0    0   0  26   0   0   3\n",
      "NP          0    1   0   0    0   0   0   3   0   0\n",
      "VN          0    0   0   0    0   0   0   0   2   1\n",
      "YF          0    0   0   0    0   0   0   0   0   1\n"
     ]
    }
   ],
   "source": [
    "# Cross-tabulated Confusion Matrix\\n\",\n",
    "# Create a DataFrame\n",
    "import pandas as pd\n",
    "data = {'Actual': y_test, 'Predicted': y_predict}\n",
    "df = pd.DataFrame(data)\n",
    "# Create the confusion matrix\n",
    "conf_matrix = pd.crosstab(df['Actual'], df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a815277-7e7b-40b8-bb70-bd40ba7f405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Precision Score : 80.63218390804596 %\n",
      "Micro Precision Score : 86.15384615384616 %\n",
      "Macro Recall Score : 77.13218390804599 %\n",
      "Micro Recall Score : 86.15384615384616 %\n",
      "Macro F1 Score : 74.10837438423646 %\n",
      "Micro F1 Score : 86.15384615384615 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate macro/micro precision, recall & f1-score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision_macro = precision_score(y_test, y_predict, average='macro')\n",
    "precision_micro = precision_score(y_test, y_predict, average='micro')\n",
    "\n",
    "recall_macro = recall_score(y_test, y_predict, average='macro')\n",
    "recall_micro = recall_score(y_test, y_predict, average='micro')\n",
    "\n",
    "f1_macro = f1_score(y_test, y_predict, average='macro')\n",
    "f1_micro = f1_score(y_test, y_predict, average='micro')\n",
    "\n",
    "# Print the results\n",
    "print(\"Macro Precision Score :\",  precision_macro*100, '%')\n",
    "print(\"Micro Precision Score :\", precision_micro*100, '%')\n",
    "\n",
    "print(\"Macro Recall Score :\", recall_macro*100, '%')\n",
    "print(\"Micro Recall Score :\", recall_micro*100, '%')\n",
    "\n",
    "print(\"Macro F1 Score :\", f1_macro*100, '%')\n",
    "print(\"Micro F1 Score :\", f1_micro*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc045e2-b247-43b0-b0ce-850b479f4ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49657d2c-c604-4467-ae5c-6e092ce8507c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
